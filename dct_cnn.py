# -*- coding: utf-8 -*-
"""dct-cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18r5QrOvUsbBetIl19F4TYuBW7x2sDvqk

dataset upload.
"""

from google.colab import files
uploaded = files.upload()

!unzip data.zip

import cv2
import numpy as np
import pywt
import torch
import torch.nn as nn
import os

def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size, size))
    return img.astype(np.float32) / 255.0

def embed_watermark(host, watermark, alpha):
    coeffs = pywt.dwt2(host, 'haar')
    LL, (LH, HL, HH) = coeffs

    wm = cv2.resize(watermark, LH.shape[::-1])

    LH_emb = LH + alpha * wm
    HL_emb = HL + alpha * wm

    return pywt.idwt2((LL, (LH_emb, HL_emb, HH)), 'haar')

def extract_watermark(wm_img, host, alpha):
    c1 = pywt.dwt2(host, 'haar')
    c2 = pywt.dwt2(wm_img, 'haar')

    LH1, HL1 = c1[1][0], c1[1][1]
    LH2, HL2 = c2[1][0], c2[1][1]

    wm = ((LH2 - LH1) + (HL2 - HL1)) / (2 * alpha)
    return np.clip(wm, 0, 1)

class AlphaNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 16, 3, 2, 1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, 2, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return 0.002 + self.net(x) * 0.018

model = AlphaNet().cuda()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

HOST_DIR = "data/host"
WM_DIR = "data/watermark"

for epoch in range(30):
    total_loss = 0

    for h in os.listdir(HOST_DIR):
        host = load_gray(os.path.join(HOST_DIR, h))
        wm = load_gray(os.path.join(WM_DIR, np.random.choice(os.listdir(WM_DIR))), size=256)

        host_t = torch.tensor(host).unsqueeze(0).unsqueeze(0).cuda()

        alpha = model(host_t).item()

        wm_img = embed_watermark(host, wm, alpha)
        wm_ext = extract_watermark(wm_img, host, alpha)

        loss = np.mean((wm_ext - wm) ** 2)
        total_loss += loss

        optimizer.zero_grad()
        torch.tensor(loss, requires_grad=True).backward()
        optimizer.step()

    print(f"Epoch {epoch}: Loss = {total_loss:.6f}")

MODEL_PATH = "/content/alpha_net.pth"
torch.save(model.state_dict(), MODEL_PATH)
print("Model saved at", MODEL_PATH)

MODEL_PATH = "/content/alpha_net.pth"
torch.save(model.state_dict(), MODEL_PATH)
print("Model saved at", MODEL_PATH)

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import cv2
import numpy as np
import os
import torch

TEST_HOST = "/content/data/host"
TEST_WM = "/content/data/watermark"
OUT_DIR = "/content/results"
os.makedirs(OUT_DIR, exist_ok=True)

for hname in os.listdir(TEST_HOST):
    host = load_gray(os.path.join(TEST_HOST, hname), size=256)
    wm = load_gray(os.path.join(TEST_WM, np.random.choice(os.listdir(TEST_WM))), size=64)

    # Predict adaptive alpha
    host_t = torch.tensor(host).unsqueeze(0).unsqueeze(0).float().to(device)
    with torch.no_grad():
        alpha = model(host_t)[0, 0].cpu().numpy()

    # Embed watermark
    watermarked = embed_watermark(host, wm, alpha)

    # Extract watermark
    extracted = extract_watermark(watermarked, host, alpha)

    # Metrics
    p = psnr(host, watermarked, data_range=1.0)
    s = ssim(host, watermarked, data_range=1.0)

    print(f"{hname} → PSNR: {p:.2f}, SSIM: {s:.4f}")

    # Save images
    cv2.imwrite(f"{OUT_DIR}/host_{hname}", (host*255).astype(np.uint8))
    cv2.imwrite(f"{OUT_DIR}/wm_{hname}", (watermarked*255).astype(np.uint8))
    cv2.imwrite(f"{OUT_DIR}/ext_{hname}", (extracted*255).astype(np.uint8))

import torch
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AlphaNet().to(device)
model.load_state_dict(torch.load("/content/alpha_net.pth", map_location=device))
model.eval()

print("✅ Model loaded")

from google.colab import files

print("Upload HOST image")
host_file = files.upload()

print("Upload WATERMARK image")
wm_file = files.upload()

host_path = list(host_file.keys())[0]
wm_path = list(wm_file.keys())[0]

# ===============================
# Watermarking Inference Code
# ===============================

import cv2
import numpy as np
import pywt
import torch
import torch.nn as nn
from matplotlib import pyplot as plt

# -------------------------------
# Load AlphaNet model
# -------------------------------
class AlphaNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 16, 3, 2, 1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, 2, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return 0.002 + self.net(x) * 0.018  # adaptive alpha between 0.002 and 0.02

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AlphaNet().to(device)
model.load_state_dict(torch.load("/content/alpha_net.pth", map_location=device))
model.eval()

# -------------------------------
# Utility functions
# -------------------------------
def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size, size))
    return img.astype(np.float32) / 255.0

def embed_watermark(host, watermark, alpha):
    coeffs = pywt.dwt2(host, 'haar')
    LL, (LH, HL, HH) = coeffs

    wm = cv2.resize(watermark, LH.shape[::-1])
    LH_emb = LH + alpha * wm
    HL_emb = HL + alpha * wm

    wm_img = pywt.idwt2((LL, (LH_emb, HL_emb, HH)), 'haar')
    return np.clip(wm_img, 0, 1)

def extract_watermark(wm_img, host, alpha):
    c1 = pywt.dwt2(host, 'haar')
    c2 = pywt.dwt2(wm_img, 'haar')

    LH1, HL1 = c1[1][0], c1[1][1]
    LH2, HL2 = c2[1][0], c2[1][1]

    wm = ((LH2 - LH1) + (HL2 - HL1)) / (2 * alpha)
    return np.clip(wm, 0, 1)

# -------------------------------
# User Input: host image & watermark
# -------------------------------
host_path = "/content/data/host/000016 (3).png"        # change to your host image path
wm_path = "/content/data/watermark/watermark.png"  # change to your watermark image path

host = load_gray(host_path)
wm = load_gray(wm_path, size=host.shape[0])

# -------------------------------
# Predict adaptive alpha
# -------------------------------
host_t = torch.tensor(host).unsqueeze(0).unsqueeze(0).float().to(device)
with torch.no_grad():
    alpha = model(host_t)[0,0].cpu().numpy()
print("Predicted alpha:", alpha)

# -------------------------------
# Embed watermark
# -------------------------------
wm_img = embed_watermark(host, wm, alpha)

# -------------------------------
# Extract watermark
# -------------------------------
wm_ext = extract_watermark(wm_img, host, alpha)

# -------------------------------
# Display results
# -------------------------------
plt.figure(figsize=(12,5))

plt.subplot(1,3,1)
plt.title("Host Image")
plt.imshow(host, cmap='gray')
plt.axis('off')

plt.subplot(1,3,2)
plt.title("Watermarked Image")
plt.imshow(wm_img, cmap='gray')
plt.axis('off')

plt.subplot(1,3,3)
plt.title("Extracted Watermark")
plt.imshow(wm_ext, cmap='gray')
plt.axis('off')

plt.show()

# ===============================
# Watermarking Inference Code with Metrics (Fixed)
# ===============================

import cv2
import numpy as np
import pywt
import torch
import torch.nn as nn
from matplotlib import pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# -------------------------------
# Load AlphaNet model
# -------------------------------
class AlphaNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 16, 3, 2, 1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, 2, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return 0.002 + self.net(x) * 0.018  # adaptive alpha between 0.002 and 0.02

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AlphaNet().to(device)
model.load_state_dict(torch.load("/content/alpha_net.pth", map_location=device))
model.eval()

# -------------------------------
# Utility functions
# -------------------------------
def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size, size))
    return img.astype(np.float32) / 255.0

def embed_watermark(host, watermark, alpha):
    coeffs = pywt.dwt2(host, 'haar')
    LL, (LH, HL, HH) = coeffs

    wm = cv2.resize(watermark, LH.shape[::-1])
    LH_emb = LH + alpha * wm
    HL_emb = HL + alpha * wm

    wm_img = pywt.idwt2((LL, (LH_emb, HL_emb, HH)), 'haar')
    return np.clip(wm_img, 0, 1)

def extract_watermark(wm_img, host, alpha):
    c1 = pywt.dwt2(host, 'haar')
    c2 = pywt.dwt2(wm_img, 'haar')

    LH1, HL1 = c1[1][0], c1[1][1]
    LH2, HL2 = c2[1][0], c2[1][1]

    wm = ((LH2 - LH1) + (HL2 - HL1)) / (2 * alpha)
    return np.clip(wm, 0, 1)

def normalized_correlation(w1, w2):
    w1_flat = w1.flatten()
    w2_flat = w2.flatten()
    nc = np.sum(w1_flat * w2_flat) / (np.sqrt(np.sum(w1_flat**2) * np.sum(w2_flat**2)) + 1e-8)
    return nc

# -------------------------------
# User Input: host image & watermark
# -------------------------------
host_path = "/content/data/host/000016 (3).png"        # change to your host image path
wm_path = "/content/data/watermark/watermark.png"     # change to your watermark image path

host = load_gray(host_path)
wm = load_gray(wm_path, size=host.shape[0])

# -------------------------------
# Predict adaptive alpha
# -------------------------------
host_t = torch.tensor(host).unsqueeze(0).unsqueeze(0).float().to(device)
with torch.no_grad():
    alpha = model(host_t)[0,0].cpu().numpy()
print("Predicted alpha:", alpha)

# -------------------------------
# Embed watermark
# -------------------------------
wm_img = embed_watermark(host, wm, alpha)

# -------------------------------
# Extract watermark
# -------------------------------
wm_ext = extract_watermark(wm_img, host, alpha)

# Resize original watermark to match extracted watermark for NC calculation
wm_resized = cv2.resize(wm, (wm_ext.shape[1], wm_ext.shape[0]))

# -------------------------------
# Compute metrics
# -------------------------------
psnr_val = psnr(host, wm_img)
ssim_val = ssim(host, wm_img, data_range=1.0)
nc_val = normalized_correlation(wm_resized, wm_ext)

print(f"PSNR (Host vs Watermarked): {psnr_val:.2f}")
print(f"SSIM (Host vs Watermarked): {ssim_val:.4f}")
print(f"NC (Watermark vs Extracted): {nc_val:.4f}")

# -------------------------------
# Display results
# -------------------------------
plt.figure(figsize=(12,5))

plt.subplot(1,3,1)
plt.title("Host Image")
plt.imshow(host, cmap='gray')
plt.axis('off')

plt.subplot(1,3,2)
plt.title("Watermarked Image")
plt.imshow(wm_img, cmap='gray')
plt.axis('off')

plt.subplot(1,3,3)
plt.title("Extracted Watermark")
plt.imshow(wm_ext, cmap='gray')
plt.axis('off')

plt.show()

"""new_approch"""

# ===============================
# Frequency-based Watermarking Training
# ===============================

!pip install pytorch_wavelets scikit-image --quiet

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import cv2
import numpy as np
from pytorch_wavelets import DWTForward, DWTInverse
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import random

# -------------------------------
# Device
# -------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------------
# Embedder Model (AlphaNet)
# -------------------------------
class Embedder(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1,16,3,2,1),
            nn.ReLU(),
            nn.Conv2d(16,32,3,2,1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32,1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return 0.002 + self.net(x) * 0.018  # alpha range 0.002-0.02

# -------------------------------
# Extractor placeholder
# -------------------------------
class Extractor(nn.Module):
    def forward(self, x):
        return x  # pass-through for now

# -------------------------------
# DWT layers
# -------------------------------
dwt = DWTForward(J=1, wave='haar').to(device)
idwt = DWTInverse(wave='haar').to(device)

# -------------------------------
# Utilities
# -------------------------------
def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size,size))
    img = torch.tensor(img/255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    return img.to(device)

def embed_frequency(host, wm, alpha):
    Yl, Yh = dwt(host)
    # Yh[0]: [B, C, 3, H/2, W/2]
    B, C, _, Hh, Wh = Yh[0].shape
    LH = Yh[0][:,:,0,:,:]
    HL = Yh[0][:,:,1,:,:]
    HH = Yh[0][:,:,2,:,:]

    wm_resized = F.interpolate(wm, size=(Hh, Wh), mode='bilinear')
    LH_emb = LH + alpha * wm_resized
    HL_emb = HL + alpha * wm_resized
    Yh_emb = torch.stack([LH_emb, HL_emb, HH], dim=2)
    wm_img = idwt((Yl, [Yh_emb]))
    return wm_img, wm_resized

def extract_frequency(wm_img, host, alpha):
    Yl_host, Yh_host = dwt(host)
    Yl_wm, Yh_wm = dwt(wm_img)

    LH_host = Yh_host[0][:,:,0,:,:]
    HL_host = Yh_host[0][:,:,1,:,:]
    LH_wm = Yh_wm[0][:,:,0,:,:]
    HL_wm = Yh_wm[0][:,:,1,:,:]

    wm_ext = (LH_wm - LH_host + HL_wm - HL_host)/(2*alpha)
    return wm_ext

def normalized_correlation(w1, w2):
    w1 = w1.flatten()
    w2 = w2.flatten()
    return (w1*w2).sum() / (torch.sqrt((w1**2).sum()*(w2**2).sum()+1e-8))

# -------------------------------
# Dataset
# -------------------------------
HOST_DIR = "data/host"
WM_DIR = "data/watermark"
epochs = 100

host_files = os.listdir(HOST_DIR)
wm_files = os.listdir(WM_DIR)

# -------------------------------
# Models and optimizers
# -------------------------------
embedder = Embedder().to(device)
extractor = Extractor().to(device)  # optional
opt_embed = optim.Adam(embedder.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# -------------------------------
# Training Loop
# -------------------------------
for epoch in range(epochs):
    total_loss = 0
    psnr_avg = 0
    ssim_avg = 0
    nc_avg = 0
    count = 0

    random.shuffle(host_files)

    for h_file in host_files:
        host = load_gray(os.path.join(HOST_DIR,h_file))
        wm_file = os.path.join(WM_DIR, random.choice(wm_files))
        wm = load_gray(wm_file, size=host.shape[-1])

        # ---- Embed ----
        alpha = embedder(host)
        wm_img, wm_resized = embed_frequency(host, wm, alpha)

        # ---- Extract ----
        wm_ext = extract_frequency(wm_img, host, alpha)

        # ---- Loss ----
        loss = criterion(wm_ext, wm_resized)

        opt_embed.zero_grad()
        loss.backward()
        opt_embed.step()

        # ---- Metrics ----
        host_np = host.squeeze().cpu().numpy()
        wm_img_np = wm_img.squeeze().detach().cpu().numpy()
        psnr_avg += psnr(host_np, wm_img_np)
        ssim_avg += ssim(host_np, wm_img_np, data_range=1.0)
        nc_avg += normalized_correlation(wm_resized, wm_ext).item()
        total_loss += loss.item()
        count += 1

    print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss/count:.6f} | PSNR: {psnr_avg/count:.2f} | SSIM: {ssim_avg/count:.4f} | NC: {nc_avg/count:.4f}")

# -------------------------------
# Save models
# -------------------------------
torch.save(embedder.state_dict(), "embedder_model.pth")
torch.save(extractor.state_dict(), "extractor_model.pth")
print("Embedder and Extractor models saved successfully!")

import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
from pytorch_wavelets import DWTForward, DWTInverse
from google.colab import files  # For image upload in Colab

# -------------------------------
# Device
# -------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------------
# Embedder Model
# -------------------------------
class Embedder(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1,16,3,2,1),
            nn.ReLU(),
            nn.Conv2d(16,32,3,2,1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32,1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return 0.002 + self.net(x) * 0.018  # alpha range

# -------------------------------
# DWT layers
# -------------------------------
dwt = DWTForward(J=1, wave='haar').to(device)
idwt = DWTInverse(wave='haar').to(device)

# -------------------------------
# Utilities
# -------------------------------
def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size, size))
    img = torch.tensor(img/255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    return img.to(device)

def embed_frequency(host, wm, alpha):
    # DWT decomposition
    Yl, Yh_list = dwt(host)
    Yh = Yh_list[0]  # Yh: [B, C, 3, H, W]

    # Extract subbands correctly
    LH = Yh[:, :, 0, :, :]
    HL = Yh[:, :, 1, :, :]
    HH = Yh[:, :, 2, :, :]

    # Resize watermark to match LH/HL
    wm_resized = F.interpolate(wm, size=LH.shape[-2:], mode='bilinear')

    # Embed watermark
    LH_emb = LH + alpha * wm_resized
    HL_emb = HL + alpha * wm_resized

    # Reconstruct Yh with embedded subbands
    Yh_emb = torch.stack([LH_emb, HL_emb, HH], dim=2)  # shape: [B, C, 3, H, W]

    # Inverse DWT
    wm_img = idwt((Yl, [Yh_emb]))
    return wm_img

# -------------------------------
# Load model
# -------------------------------
embedder = Embedder().to(device)
embedder.load_state_dict(torch.load("embedder_model.pth", map_location=device))
embedder.eval()

# -------------------------------
# Upload images
# -------------------------------
print("Upload your host image:")
uploaded = files.upload()
host_path = list(uploaded.keys())[0]

print("Upload your watermark image:")
uploaded = files.upload()
wm_path = list(uploaded.keys())[0]

host = load_gray(host_path)
wm = load_gray(wm_path, size=host.shape[-1])

# ---- Embed ----
with torch.no_grad():
    alpha = embedder(host)
    wm_img = embed_frequency(host, wm, alpha)

# ---- Save watermarked image ----
wm_img_np = wm_img.squeeze().cpu().numpy()
cv2.imwrite("watermarked_image.png", (wm_img_np*255).astype('uint8'))
print("Watermarked image saved as watermarked_image.png")

import torch
import torch.nn as nn
import cv2
import torch.nn.functional as F
from pytorch_wavelets import DWTForward
from google.colab import files  # For image upload in Colab

# -------------------------------
# Device
# -------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------------
# Utilities
# -------------------------------
def load_gray(path, size=512):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (size, size))
    img = torch.tensor(img/255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    return img.to(device)

# -------------------------------
# DWT forward
# -------------------------------
dwt = DWTForward(J=1, wave='haar').to(device)

# -------------------------------
# Extract watermark
# -------------------------------
def extract_frequency(wm_img, host, alpha):
    Yl_host, Yh_host_list = dwt(host)
    Yl_wm, Yh_wm_list = dwt(wm_img)

    Yh_host = Yh_host_list[0]
    Yh_wm = Yh_wm_list[0]

    LH_host = Yh_host[:, :, 0, :, :]
    HL_host = Yh_host[:, :, 1, :, :]

    LH_wm = Yh_wm[:, :, 0, :, :]
    HL_wm = Yh_wm[:, :, 1, :, :]

    # Extract watermark from LH and HL
    wm_extracted = ( (LH_wm - LH_host) + (HL_wm - HL_host) ) / (2*alpha)
    return wm_extracted

# -------------------------------
# Upload images
# -------------------------------
print("Upload the watermarked image:")
uploaded = files.upload()
wm_img_path = list(uploaded.keys())[0]

print("Upload the original host image:")
uploaded = files.upload()
host_path = list(uploaded.keys())[0]

# -------------------------------
# Load images
# -------------------------------
wm_img = load_gray(wm_img_path)
host = load_gray(host_path)

# -------------------------------
# Set alpha (must match the one used in embedder)
# -------------------------------
alpha_value = 0.01  # You can adjust or calculate from embedder output

# -------------------------------
# Extract watermark
# -------------------------------
with torch.no_grad():
    wm_extracted = extract_frequency(wm_img, host, alpha_value)

# ---- Save extracted watermark ----
wm_extracted_np = wm_extracted.squeeze().cpu().numpy()
cv2.imwrite("extracted_watermark.png", (wm_extracted_np*255).astype('uint8'))
print("Extracted watermark saved as extracted_watermark.png")

