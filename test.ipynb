{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2991ff57",
   "metadata": {},
   "source": [
    "embedder code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd277d6",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from google.colab import files  # For image upload in Colab\n",
    "\n",
    "# -------------------------------\n",
    "# Device\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# Embedder Model\n",
    "# -------------------------------\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3,2,1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return 0.002 + self.net(x) * 0.018  # alpha range\n",
    "\n",
    "# -------------------------------\n",
    "# DWT layers\n",
    "# -------------------------------\n",
    "dwt = DWTForward(J=1, wave='haar').to(device)\n",
    "idwt = DWTInverse(wave='haar').to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def load_gray(path, size=512):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = torch.tensor(img/255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    return img.to(device)\n",
    "\n",
    "def embed_frequency(host, wm, alpha):\n",
    "    # DWT decomposition\n",
    "    Yl, Yh_list = dwt(host)\n",
    "    Yh = Yh_list[0]  # Yh: [B, C, 3, H, W]\n",
    "\n",
    "    # Extract subbands correctly\n",
    "    LH = Yh[:, :, 0, :, :]\n",
    "    HL = Yh[:, :, 1, :, :]\n",
    "    HH = Yh[:, :, 2, :, :]\n",
    "\n",
    "    # Resize watermark to match LH/HL\n",
    "    wm_resized = F.interpolate(wm, size=LH.shape[-2:], mode='bilinear')\n",
    "\n",
    "    # Embed watermark\n",
    "    LH_emb = LH + alpha * wm_resized\n",
    "    HL_emb = HL + alpha * wm_resized\n",
    "\n",
    "    # Reconstruct Yh with embedded subbands\n",
    "    Yh_emb = torch.stack([LH_emb, HL_emb, HH], dim=2)  # shape: [B, C, 3, H, W]\n",
    "\n",
    "    # Inverse DWT\n",
    "    wm_img = idwt((Yl, [Yh_emb]))\n",
    "    return wm_img\n",
    "\n",
    "# -------------------------------\n",
    "# Load model\n",
    "# -------------------------------\n",
    "embedder = Embedder().to(device)\n",
    "embedder.load_state_dict(torch.load(\"embedder_model.pth\", map_location=device))\n",
    "embedder.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# Upload images\n",
    "# -------------------------------\n",
    "print(\"Upload your host image:\")\n",
    "uploaded = files.upload()\n",
    "host_path = list(uploaded.keys())[0]\n",
    "\n",
    "print(\"Upload your watermark image:\")\n",
    "uploaded = files.upload()\n",
    "wm_path = list(uploaded.keys())[0]\n",
    "\n",
    "host = load_gray(host_path)\n",
    "wm = load_gray(wm_path, size=host.shape[-1])\n",
    "\n",
    "# ---- Embed ----\n",
    "with torch.no_grad():\n",
    "    alpha = embedder(host)\n",
    "    wm_img = embed_frequency(host, wm, alpha)\n",
    "\n",
    "# ---- Save watermarked image ----\n",
    "wm_img_np = wm_img.squeeze().cpu().numpy()\n",
    "cv2.imwrite(\"watermarked_image.png\", (wm_img_np*255).astype('uint8'))\n",
    "print(\"Watermarked image saved as watermarked_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d920e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "extractor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58945d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from pytorch_wavelets import DWTForward\n",
    "from google.colab import files  # For image upload in Colab\n",
    "\n",
    "# -------------------------------\n",
    "# Device\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def load_gray(path, size=512):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = torch.tensor(img/255.0, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    return img.to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# DWT forward\n",
    "# -------------------------------\n",
    "dwt = DWTForward(J=1, wave='haar').to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# Extract watermark\n",
    "# -------------------------------\n",
    "def extract_frequency(wm_img, host, alpha):\n",
    "    Yl_host, Yh_host_list = dwt(host)\n",
    "    Yl_wm, Yh_wm_list = dwt(wm_img)\n",
    "\n",
    "    Yh_host = Yh_host_list[0]\n",
    "    Yh_wm = Yh_wm_list[0]\n",
    "\n",
    "    LH_host = Yh_host[:, :, 0, :, :]\n",
    "    HL_host = Yh_host[:, :, 1, :, :]\n",
    "\n",
    "    LH_wm = Yh_wm[:, :, 0, :, :]\n",
    "    HL_wm = Yh_wm[:, :, 1, :, :]\n",
    "\n",
    "    # Extract watermark from LH and HL\n",
    "    wm_extracted = ( (LH_wm - LH_host) + (HL_wm - HL_host) ) / (2*alpha)\n",
    "    return wm_extracted\n",
    "\n",
    "# -------------------------------\n",
    "# Upload images\n",
    "# -------------------------------\n",
    "print(\"Upload the watermarked image:\")\n",
    "uploaded = files.upload()\n",
    "wm_img_path = list(uploaded.keys())[0]\n",
    "\n",
    "print(\"Upload the original host image:\")\n",
    "uploaded = files.upload()\n",
    "host_path = list(uploaded.keys())[0]\n",
    "\n",
    "# -------------------------------\n",
    "# Load images\n",
    "# -------------------------------\n",
    "wm_img = load_gray(wm_img_path)\n",
    "host = load_gray(host_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Set alpha (must match the one used in embedder)\n",
    "# -------------------------------\n",
    "alpha_value = 0.01  # You can adjust or calculate from embedder output\n",
    "\n",
    "# -------------------------------\n",
    "# Extract watermark\n",
    "# -------------------------------\n",
    "with torch.no_grad():\n",
    "    wm_extracted = extract_frequency(wm_img, host, alpha_value)\n",
    "\n",
    "# ---- Save extracted watermark ----\n",
    "wm_extracted_np = wm_extracted.squeeze().cpu().numpy()\n",
    "cv2.imwrite(\"extracted_watermark.png\", (wm_extracted_np*255).astype('uint8'))\n",
    "print(\"Extracted watermark saved as extracted_watermark.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
